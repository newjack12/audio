# 算法说明（工业级思路）

本项目把“哼唱/人声/弦乐/钢琴 -> 旋律 + 和弦(可选)”拆成工业界常见的三段式：

1) **音频前端**：统一采样率/响度/滤波/去噪（保证模型输入分布稳定）
2) **主模型（可插拔后端）**：
   - **CREPE / pYIN**：单声部 F0 跟踪（哼唱、人声、单旋律乐器）
   - **Basic Pitch / piano_transcription_inference**：多音符转写（钢琴/多声部）
3) **后处理（工程落地关键）**：
   - 多声部 -> 单旋律：使用 **动态规划 (Viterbi)** 选择最“像主旋律”的路径
   - 短音过滤、同音合并
   - 调性估计 + 轻量音级吸附（意图还原）
   - 和弦（可选）：模板匹配基线 / Omnizart Harmony Transformer

## 关键点

- **“工业级”核心不是只换一个模型**：而是让输入更干净、输出更稳定、参数可控、可监控。
- **哼唱/人声**对模型最敏感：优先用单声部 F0（CREPE/pYIN）+ 再分段成音符。
- **钢琴**需要强模型：推荐 piano_transcription_inference（若可装 PyTorch）；不行则回退 Basic Pitch。

